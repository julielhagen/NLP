{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13215925",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e176e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3efe716",
   "metadata": {},
   "source": [
    "# Reading in data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa18c39",
   "metadata": {},
   "source": [
    "silver data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78952bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, ...\n",
       "1           [0, 1, 2, 0, 1, 2, 0, 0, 3, 4, 0, 0, 0, 0]\n",
       "2                                            [3, 4, 4]\n",
       "3                       [0, 5, 6, 6, 0, 0, 0, 0, 0, 0]\n",
       "4                                [1, 2, 2, 0, 3, 4, 0]\n",
       "Name: ner_tags, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read\n",
    "silver_test = pd.read_parquet('test-00000-of-00001.parquet')\n",
    "silver_labels = silver_test[\"ner_tags\"][:200]\n",
    "silver_labels.drop(silver_labels.index[68], inplace=True)\n",
    "\n",
    "silver_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a295df4",
   "metadata": {},
   "source": [
    "gold data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db28b212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>Sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,5,0,0,0]</td>\n",
       "      <td>[ \"Shortly\", \"afterward\", \",\", \"an\", \"encourag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0,1,2,0,1,2,0,0,0,0,0,0,0,0]</td>\n",
       "      <td>[ \":\", \"Kanye\", \"West\", \"featuring\", \"Jamie\", ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[3,4,4]</td>\n",
       "      <td>[ \"Blacktown\", \"railway\", \"station\" ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0,0,0,0,0,0,1,0,0,0]</td>\n",
       "      <td>[ \"''\", \"Mycalesis\", \"perseus\", \"lalassis\", \"'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1,2,2,0,0,0,0]</td>\n",
       "      <td>[ \"Jonny\", \"Lee\", \"Miller\", \"-\", \"Eli\", \"Stone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>[1,2,0,0,0]</td>\n",
       "      <td>[ \"Wesley\", \"Pruden\", \"(\", \"2013\", \")\" ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3...</td>\n",
       "      <td>[ \"Previews\", \"are\", \"scheduled\", \"to\", \"begin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>[5,0,5,0,5]</td>\n",
       "      <td>[ \"China\", \",\", \"Indonesia\", \",\", \"Vietnam\" ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>[3,4,4,4,4,4]</td>\n",
       "      <td>[ \"Emmett\", \"/\", \"Furla\", \"/\", \"Oasis\", \"Films\" ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>[1,2,0,1,2]</td>\n",
       "      <td>[ \"Ekaterina\", \"Petaikina\", \"/\", \"Maxim\", \"Kur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Labels  \\\n",
       "0            [0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,5,0,0,0]   \n",
       "1                        [0,1,2,0,1,2,0,0,0,0,0,0,0,0]   \n",
       "2                                              [3,4,4]   \n",
       "3                                [0,0,0,0,0,0,1,0,0,0]   \n",
       "4                                      [1,2,2,0,0,0,0]   \n",
       "..                                                 ...   \n",
       "194                                        [1,2,0,0,0]   \n",
       "195  [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3...   \n",
       "196                                        [5,0,5,0,5]   \n",
       "197                                      [3,4,4,4,4,4]   \n",
       "198                                        [1,2,0,1,2]   \n",
       "\n",
       "                                             Sentences  \n",
       "0    [ \"Shortly\", \"afterward\", \",\", \"an\", \"encourag...  \n",
       "1    [ \":\", \"Kanye\", \"West\", \"featuring\", \"Jamie\", ...  \n",
       "2                [ \"Blacktown\", \"railway\", \"station\" ]  \n",
       "3    [ \"''\", \"Mycalesis\", \"perseus\", \"lalassis\", \"'...  \n",
       "4    [ \"Jonny\", \"Lee\", \"Miller\", \"-\", \"Eli\", \"Stone...  \n",
       "..                                                 ...  \n",
       "194           [ \"Wesley\", \"Pruden\", \"(\", \"2013\", \")\" ]  \n",
       "195  [ \"Previews\", \"are\", \"scheduled\", \"to\", \"begin...  \n",
       "196      [ \"China\", \",\", \"Indonesia\", \",\", \"Vietnam\" ]  \n",
       "197  [ \"Emmett\", \"/\", \"Furla\", \"/\", \"Oasis\", \"Films\" ]  \n",
       "198  [ \"Ekaterina\", \"Petaikina\", \"/\", \"Maxim\", \"Kur...  \n",
       "\n",
       "[199 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_eng = pd.read_csv(\"gold_eng.csv\", sep=\";\")\n",
    "columns_to_drop = ['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4']\n",
    "gold_eng.drop(columns=columns_to_drop, inplace=True)\n",
    "# Drop the last row explicitly by index\n",
    "gold_eng.drop(gold_eng.index[-1], inplace=True)\n",
    "gold_eng.drop(gold_eng.index[-1], inplace=True)\n",
    "gold_eng\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0617471",
   "metadata": {},
   "source": [
    "converting to list of list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7482861",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_words = gold_eng[\"Sentences\"].values.tolist()\n",
    "gold_labels = gold_eng[\"Labels\"].values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54e6eeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_labels_list=[(string_list).tolist() for string_list in silver_labels]\n",
    "gold_labels_list=[eval(string_list) for string_list in gold_labels]\n",
    "gold_word_list = [eval(string_list) for string_list in gold_words]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb12712a",
   "metadata": {},
   "source": [
    "# preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35c1ba83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, Trainer\n",
    "\n",
    "model_checkpoint = \"bert-base-multilingual-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53ef388d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "label_all_tokens = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "637a715a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(sentences, tags, tokenizer):\n",
    "    tokenized_inputs = tokenizer(sentences, truncation=True, is_split_into_words=True, padding=True)\n",
    "\n",
    "    aligned_labels = []\n",
    "    for i, label in enumerate(pd.Series(tags)):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        aligned_labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = aligned_labels\n",
    "    return tokenized_inputs.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd2da9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_gold_data = tokenize_and_align_labels(gold_word_list, gold_labels_list, tokenizer)\n",
    "tokenized_silver_data = tokenize_and_align_labels(gold_word_list, silver_labels_list, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6484b021",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenized_gold_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1fad0bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ded1318",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_dataset = Dataset.from_dict({\n",
    "    'id': range(len(tokenized_gold_data['input_ids'])),\n",
    "    'input_ids': tokenized_gold_data['input_ids'],\n",
    "    'attention_mask': tokenized_gold_data['attention_mask'],\n",
    "    'labels': tokenized_gold_data['labels']\n",
    "})\n",
    "\n",
    "\n",
    "silver_dataset = Dataset.from_dict({\n",
    "    'id': range(len(tokenized_silver_data['input_ids'])),\n",
    "    'input_ids': tokenized_silver_data['input_ids'],\n",
    "    'attention_mask': tokenized_silver_data['attention_mask'],\n",
    "    'labels': tokenized_silver_data['labels']\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8aca7dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save gold_dataset\n",
    "with open('mbert_eng_gold_gold_dataset.pickle', 'wb') as f:\n",
    "    pickle.dump(gold_dataset, f)\n",
    "\n",
    "# Save silver_dataset\n",
    "with open('mbert_eng_gold_silver_dataset.pickle', 'wb') as f:\n",
    "    pickle.dump(silver_dataset, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b40d3a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec92f97e",
   "metadata": {},
   "source": [
    "# Quality checking lengths of the annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ac482fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are lengths equal and aligned: True\n"
     ]
    }
   ],
   "source": [
    "# Check if lengths are equal and aligned\n",
    "lengths_equal = all(len(gold_labels) == len(sentences) for gold_labels, sentences in zip(gold_labels_list, gold_word_list))\n",
    "\n",
    "print(\"Are lengths equal and aligned:\", lengths_equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa31d574",
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_labels_list = [(string_list).tolist() for string_list in silver_labels]\n",
    "gold_labels_list = [eval(string_list) for string_list in gold_labels]\n",
    "gold_word_list = [eval(string_list) for string_list in gold_words]\n",
    "\n",
    "# Check if all lists have the same length at each index\n",
    "for i in range(min(len(silver_labels_list), len(gold_labels_list), len(gold_word_list))):\n",
    "    silver_len = len(silver_labels_list[i])\n",
    "    gold_len = len(gold_labels_list[i])\n",
    "    word_len = len(gold_word_list[i])\n",
    "    \n",
    "    if silver_len != gold_len or silver_len != word_len:\n",
    "        print(f\"At index {i}: Silver labels length = {silver_len}, Gold labels length = {gold_len}, Gold words length = {word_len}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8e878a",
   "metadata": {},
   "source": [
    "# using test data on saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b318193",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#gold_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3e451e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, Trainer,AutoModelForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "04e82596",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = AutoModelForTokenClassification.from_pretrained(\"eng_mbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "939a958a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062047b1",
   "metadata": {},
   "source": [
    "import pickle\n",
    "\n",
    "with open('gold_dataset.pickle','rb') as f:\n",
    "    eng_gold = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b41b7201",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W socket.cpp:464] [c10d] The server socket has failed to bind to [::]:49487 (errno: 98 - Address already in use).\n",
      "[W socket.cpp:464] [c10d] The server socket has failed to bind to 0.0.0.0:49487 (errno: 98 - Address already in use).\n",
      "[E socket.cpp:500] [c10d] The server socket has failed to listen on any local network address.\n"
     ]
    },
    {
     "ename": "DistNetworkError",
     "evalue": "The server socket has failed to listen on any local network address. The server socket has failed to bind to [::]:49487 (errno: 98 - Address already in use). The server socket has failed to bind to 0.0.0.0:49487 (errno: 98 - Address already in use).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDistNetworkError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloaded_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:380\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    378\u001b[0m     output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtmp_trainer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    379\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo `TrainingArguments` passed, using `output_dir=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 380\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m args\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# Seed must be set before instantiating the model when using model\u001b[39;00m\n",
      "File \u001b[0;32m<string>:125\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, dataloader_persistent_workers, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, gradient_checkpointing_kwargs, include_inputs_for_metrics, eval_do_concat_batches, fp16_backend, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, dispatch_batches, split_batches, include_tokens_per_second, include_num_input_tokens_seen, neftune_noise_alpha, optim_target_modules)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/training_args.py:1605\u001b[0m, in \u001b[0;36mTrainingArguments.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m version\u001b[38;5;241m.\u001b[39mparse(version\u001b[38;5;241m.\u001b[39mparse(torch\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mbase_version) \u001b[38;5;241m==\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp16:\n\u001b[1;32m   1600\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--optim adamw_torch_fused with --fp16 requires PyTorch>2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1602\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1603\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1604\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_torch_available()\n\u001b[0;32m-> 1605\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1606\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1607\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1608\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1609\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (get_xla_device_type(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   1610\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp16 \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp16_full_eval)\n\u001b[1;32m   1611\u001b[0m ):\n\u001b[1;32m   1612\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1613\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1614\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (`--fp16_full_eval`) can only be used on CUDA or MLU devices or NPU devices or certain XPU devices (with IPEX).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1615\u001b[0m     )\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1618\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1619\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_torch_available()\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1627\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbf16 \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbf16_full_eval)\n\u001b[1;32m   1628\u001b[0m ):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/training_args.py:2094\u001b[0m, in \u001b[0;36mTrainingArguments.device\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2090\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2091\u001b[0m \u001b[38;5;124;03mThe device used by this process.\u001b[39;00m\n\u001b[1;32m   2092\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2093\u001b[0m requires_backends(\u001b[38;5;28mself\u001b[39m, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m-> 2094\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_devices\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/generic.py:63\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[0;34m(self, obj, objtype)\u001b[0m\n\u001b[1;32m     61\u001b[0m cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, attr, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 63\u001b[0m     cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(obj, attr, cached)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cached\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/training_args.py:2026\u001b[0m, in \u001b[0;36mTrainingArguments._setup_devices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2024\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_gpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2025\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2026\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistributed_state \u001b[38;5;241m=\u001b[39m \u001b[43mPartialState\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2027\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mddp_backend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimedelta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mddp_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2028\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2029\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_gpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2030\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_sagemaker_mp_enabled():\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/accelerate/state.py:213\u001b[0m, in \u001b[0;36mPartialState.__init__\u001b[0;34m(self, cpu, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;66;03m# Deal with all other backends but XPU and CPU, that gets handled special later\u001b[39;00m\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    210\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (DistributedType\u001b[38;5;241m.\u001b[39mMULTI_XPU, DistributedType\u001b[38;5;241m.\u001b[39mMULTI_CPU)\n\u001b[1;32m    211\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mdistributed\u001b[38;5;241m.\u001b[39mis_initialized()\n\u001b[1;32m    212\u001b[0m         ):\n\u001b[0;32m--> 213\u001b[0m             \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_process_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;66;03m# XPU and CPU require special env configs to be set\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;129;01min\u001b[39;00m (DistributedType\u001b[38;5;241m.\u001b[39mMULTI_XPU, DistributedType\u001b[38;5;241m.\u001b[39mMULTI_CPU):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py:75\u001b[0m, in \u001b[0;36m_exception_logger.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: _P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: _P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _T:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 75\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m     77\u001b[0m         msg_dict \u001b[38;5;241m=\u001b[39m _get_msg_dict(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py:89\u001b[0m, in \u001b[0;36m_time_logger.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: _P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: _P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _T:\n\u001b[1;32m     88\u001b[0m     t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime_ns()\n\u001b[0;32m---> 89\u001b[0m     func_return \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     time_spent \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime_ns() \u001b[38;5;241m-\u001b[39m t1\n\u001b[1;32m     92\u001b[0m     msg_dict \u001b[38;5;241m=\u001b[39m _get_msg_dict(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py:1235\u001b[0m, in \u001b[0;36minit_process_group\u001b[0;34m(backend, init_method, timeout, world_size, rank, store, group_name, pg_options, device_id)\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m store \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1232\u001b[0m     rendezvous_iterator \u001b[38;5;241m=\u001b[39m rendezvous(\n\u001b[1;32m   1233\u001b[0m         not_none(init_method), rank, world_size, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m   1234\u001b[0m     )\n\u001b[0;32m-> 1235\u001b[0m     store, rank, world_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrendezvous_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1236\u001b[0m     store\u001b[38;5;241m.\u001b[39mset_timeout(timeout)\n\u001b[1;32m   1238\u001b[0m     \u001b[38;5;66;03m# Use a PrefixStore to avoid accidental overrides of keys used by\u001b[39;00m\n\u001b[1;32m   1239\u001b[0m     \u001b[38;5;66;03m# different systems (e.g. RPC) in case the store is multi-tenant.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/distributed/rendezvous.py:246\u001b[0m, in \u001b[0;36m_env_rendezvous_handler\u001b[0;34m(url, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m master_port \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(_get_env_or_raise(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMASTER_PORT\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    244\u001b[0m use_libuv \u001b[38;5;241m=\u001b[39m query_dict\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_libuv\u001b[39m\u001b[38;5;124m\"\u001b[39m, os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSE_LIBUV\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 246\u001b[0m store \u001b[38;5;241m=\u001b[39m \u001b[43m_create_c10d_store\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaster_addr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaster_port\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_libuv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m (store, rank, world_size)\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# If this configuration is invalidated, there is nothing we can do about it\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/distributed/rendezvous.py:174\u001b[0m, in \u001b[0;36m_create_c10d_store\u001b[0;34m(hostname, port, rank, world_size, timeout, use_libuv)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    173\u001b[0m     start_daemon \u001b[38;5;241m=\u001b[39m rank \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTCPStore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhostname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_daemon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_tenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_libuv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_libuv\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mDistNetworkError\u001b[0m: The server socket has failed to listen on any local network address. The server socket has failed to bind to [::]:49487 (errno: 98 - Address already in use). The server socket has failed to bind to 0.0.0.0:49487 (errno: 98 - Address already in use)."
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model = loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8401e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(silver_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0b38c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.predict(silver_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121fe5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af86637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ed5732",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: '0',\n",
    "            1: 'B-PER', \n",
    "            2: 'I-PER',\n",
    "            3: 'B-ORG',\n",
    "            4: 'I-ORG',\n",
    "            5: 'B-LOC',\n",
    "            6: 'I-LOC'\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c65335",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {label: id for id, label in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5243c972",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = list(label2id.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afd1dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04065422",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca26160",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, labels, metrics = trainer.predict(silver_dataset)\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "true_predictions = [\n",
    "    [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "true_labels = [\n",
    "    [label_names[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "\n",
    "results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c788f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9070efd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(true_predictions)):\n",
    "    print(\"Example\", i+1)\n",
    "    print(\"Predicted:\", true_predictions[i])\n",
    "    print(\"Real:\", true_labels[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294a49a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743cc59e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb9eacb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6714d2d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75d0a09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
